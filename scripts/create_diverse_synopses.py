#!/usr/bin/env python3
"""
üé≠ Script para criar sinopses mais diversas e testar clustering
"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import joblib
import os
import re

def clean_text(text):
    """Limpar e pr√©-processar texto"""
    if pd.isna(text):
        return ""
    
    text = str(text).lower()
    text = re.sub(r'[^a-z√°√†√¢√£√©√®√™√≠√¨√Æ√≥√≤√¥√µ√∫√π√ª√ß\s]', ' ', text)
    
    # Stopwords b√°sicas
    stopwords_list = ['o', 'a', 'os', 'as', 'um', 'uma', 'de', 'da', 'do', 'das', 'dos', 'em', 'na', 'no', 'nas', 'nos', 'para', 'por', 'com', 'sem', 'sobre', 'entre', 'at√©', 'ap√≥s', 'durante', 'e', 'ou', 'mas', 'se', 'que', 'quando', 'onde', 'como', 'porque', 'ent√£o', 'tamb√©m', 'muito', 'mais', 'menos', 'bem', 'mal', 'sempre', 'nunca', 'j√°', 'ainda', 's√≥', 'apenas', 'at√©', 'depois', 'antes', 'agora', 'hoje', 'ontem', 'amanh√£']
    words = text.split()
    words = [word for word in words if word not in stopwords_list and len(word) > 2]
    
    return ' '.join(words)

def create_diverse_synopses():
    """Criar sinopses mais diversas"""
    print("üé≠ Criando sinopses diversas...")
    
    # Sinopses com temas muito diferentes
    diverse_synopses = [
        # A√ß√£o/Super-her√≥i
        "Um vigilante mascarado protege sua cidade de criminosos perigosos, enfrentando dilemas morais sobre justi√ßa e vingan√ßa",
        
        # Romance/Drama
        "Dois jovens de classes sociais diferentes se apaixonam, mas precisam superar preconceitos e obst√°culos familiares para ficarem juntos",
        
        # Fic√ß√£o Cient√≠fica
        "Um grupo de astronautas embarca em uma miss√£o espacial para salvar a humanidade, descobrindo segredos sobre o universo e a exist√™ncia",
        
        # Terror/Suspense
        "Uma fam√≠lia se muda para uma casa assombrada e descobre que os esp√≠ritos dos antigos moradores ainda habitam o local, causando eventos sobrenaturais",
        
        # Com√©dia
        "Um grupo de amigos embarca em uma viagem maluca que resulta em uma s√©rie de situa√ß√µes hil√°rias e mal-entendidos c√¥micos",
        
        # Drama Hist√≥rico
        "Durante a Segunda Guerra Mundial, um soldado deve escolher entre seguir ordens ou salvar civis inocentes, enfrentando dilemas √©ticos profundos",
        
        # Mist√©rio/Detetive
        "Um detetive investiga uma s√©rie de assassinatos brutais em uma cidade pequena, descobrindo segredos sombrios que envolvem a elite local",
        
        # Fantasia
        "Um jovem descobre que √© o herdeiro de um reino m√°gico e deve aprender a usar seus poderes para salvar seu mundo de uma amea√ßa sombria",
        
        # Western
        "Um pistoleiro solit√°rio chega a uma cidade do Velho Oeste e deve escolher entre a lei e a justi√ßa quando confrontado com um bandido not√≥rio",
        
        # Musical
        "Uma jovem cantora sonha em se tornar famosa, mas deve superar obst√°culos e preconceitos para alcan√ßar seu sonho na Broadway"
    ]
    
    # Carregar dataset
    try:
        df = pd.read_csv('imdb_100plus_with_clusters.csv', sep=';')
        print(f"‚úÖ Dataset carregado: {len(df)} filmes")
    except:
        try:
            df = pd.read_csv('imdb_50plus_with_clusters.csv', sep=';')
            print(f"‚úÖ Dataset carregado: {len(df)} filmes")
        except:
            df = pd.read_csv('imdb_top250_with_clusters.csv', sep=';')
            print(f"‚úÖ Dataset carregado: {len(df)} filmes")
    
    # Limpar sinopses existentes
    df['sinopse_clean'] = df['sinopse'].apply(clean_text)
    
    # TF-IDF Vectorization
    print("üî§ Aplicando TF-IDF...")
    tfidf_vectorizer = TfidfVectorizer(
        max_features=300,
        min_df=1,
        max_df=0.9,
        ngram_range=(1, 2)
    )
    
    tfidf_matrix = tfidf_vectorizer.fit_transform(df['sinopse_clean'])
    print(f"üìä Matriz TF-IDF: {tfidf_matrix.shape}")
    
    # KMeans com par√¢metros otimizados
    print("ü§ñ Treinando KMeans...")
    kmeans_tfidf = KMeans(
        n_clusters=5,
        random_state=42,
        n_init=50,  # Muitas inicializa√ß√µes
        max_iter=500,  # Muitas itera√ß√µes
        init='k-means++',
        algorithm='lloyd'  # Algoritmo mais est√°vel
    )
    
    df['cluster_tfidf'] = kmeans_tfidf.fit_predict(tfidf_matrix)
    
    # Verificar distribui√ß√£o
    print(f"\nüìä Distribui√ß√£o dos clusters:")
    cluster_counts = df['cluster_tfidf'].value_counts().sort_index()
    for cluster_id, count in cluster_counts.items():
        print(f"  Cluster {cluster_id}: {count} filmes")
    
    # Salvar modelos
    os.makedirs('models', exist_ok=True)
    joblib.dump(kmeans_tfidf, 'models/kmeans_tfidf.pkl')
    joblib.dump(tfidf_vectorizer, 'models/tfidf_vectorizer.pkl')
    
    # Salvar dataset atualizado
    df.to_csv('imdb_100plus_with_clusters_diverse.csv', index=False, sep=';')
    
    print(f"\n‚úÖ Modelos salvos!")
    
    # Testar predi√ß√µes com sinopses diversas
    print(f"\nüß™ Testando predi√ß√µes com sinopses diversas:")
    for i, synopsis in enumerate(diverse_synopses, 1):
        clean_synopsis = clean_text(synopsis)
        synopsis_vector = tfidf_vectorizer.transform([clean_synopsis])
        predicted_cluster = kmeans_tfidf.predict(synopsis_vector)[0]
        
        # Calcular dist√¢ncias
        distances = kmeans_tfidf.transform(synopsis_vector)[0]
        min_dist = min(distances)
        max_dist = max(distances)
        diversity = max_dist - min_dist
        
        print(f"  {i}. {synopsis[:60]}...")
        print(f"     Cluster: {predicted_cluster}, Diversidade: {diversity:.3f}")
        print(f"     Dist√¢ncias: {[f'{d:.3f}' for d in distances]}")
    
    # Verificar se h√° diversidade nas predi√ß√µes
    print(f"\nüìä An√°lise de diversidade:")
    clusters_predicted = []
    for synopsis in diverse_synopses:
        clean_synopsis = clean_text(synopsis)
        synopsis_vector = tfidf_vectorizer.transform([clean_synopsis])
        predicted_cluster = kmeans_tfidf.predict(synopsis_vector)[0]
        clusters_predicted.append(predicted_cluster)
    
    unique_clusters = set(clusters_predicted)
    print(f"  Clusters √∫nicos preditos: {len(unique_clusters)}")
    print(f"  Clusters: {sorted(unique_clusters)}")
    
    if len(unique_clusters) == 1:
        print("‚ö†Ô∏è ATEN√á√ÉO: Todas as sinopses ainda est√£o sendo classificadas no mesmo cluster!")
        print("üîç Poss√≠veis causas:")
        print("  - Dataset com sinopses muito similares")
        print("  - Modelo de clustering inadequado")
        print("  - Features insuficientes para diferencia√ß√£o")
    else:
        print("‚úÖ Diversidade de clusters detectada!")

if __name__ == '__main__':
    create_diverse_synopses()
